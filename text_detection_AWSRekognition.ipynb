{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Rekognition Text Detection Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3_resource = boto3.resource('s3')\n",
    "client=boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (UnrecognizedClientException) when calling the DetectText operation: The security token included in the request is invalid.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-91af121ba296>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mphoto\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'00007-4883-13_DB18ED97.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'S3Object'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Bucket'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbucket\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Name'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mphoto\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtextDetections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TextDetections'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\environ1\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[0;32m    356\u001b[0m             \u001b[1;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\environ1\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    659\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Code\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mClientError\u001b[0m: An error occurred (UnrecognizedClientException) when calling the DetectText operation: The security token included in the request is invalid."
     ]
    }
   ],
   "source": [
    "bucket='secondpythonbucket6ce9cccf-c429-471c-99a1-f36e849ee381'\n",
    "photo='00007-4883-13_DB18ED97.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    if text['Id'] < 7:\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "        print('\\n')\n",
    "        # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pill_img = imageio.imread('./pillbox_images/00007-4883-13_DB18ED97.jpg')\n",
    "plt.imshow(pill_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo='009045988.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    #if text['Id'] < 7:\n",
    "    print ('Detected text:' + text['DetectedText'])\n",
    "    print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "    print('\\n')\n",
    "    # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pill_img = imageio.imread('./pillbox_images/009045988.jpg')\n",
    "plt.imshow(pill_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo='006035484.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    if (text['Id'] < 7) & (text['Confidence'] > 85):\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "        print('\\n')\n",
    "        # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pill_img = imageio.imread('./pillbox_images/006035484.jpg')\n",
    "plt.imshow(pill_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo='007773107.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    if (text['Id'] < 7) & (text['Confidence'] > 85):\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "        print('\\n')\n",
    "        # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pill_img = imageio.imread('./pillbox_images/007773107.jpg')\n",
    "plt.imshow(pill_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to manipulate an image from S3 Bucket\n",
    "\n",
    "We'll try to cut the image in half to split into 2 images \n",
    "(To mimic a scenario where a user will send pictures of front and back of pill)\n",
    "\n",
    "Then we'll seek to read text from each and keep unique pieces of text (but only those with \"Confidence\" > 85%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo='007811655.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    if (text['Id'] < 7) & (text['Confidence'] > 85):\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "        print('\\n')\n",
    "        # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get url of file uploaded on AWS S3 bucket?\n",
    "\n",
    "https://region_name.amazonaws.com/buket_name/object_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Image from S3 and Splitting into 2 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading image\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "s3_resource.Object(bucket, photo).download_file(f'./{photo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pic = imageio.imread('./007811655.jpg')\n",
    "plt.imshow(pic);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = pic.shape[:2]\n",
    "\n",
    "# Cut the image in half\n",
    "height_cutoff = height // 2\n",
    "s1 = pic[:height_cutoff,:]\n",
    "s2 = pic[height_cutoff:,:]\n",
    "\n",
    "# Save each half\n",
    "imageio.imwrite('img1.png', s1)\n",
    "imageio.imwrite('img2.png', s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic1 = imageio.imread('./img1.png')\n",
    "plt.imshow(pic1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic2 = imageio.imread('./img2.png')\n",
    "plt.imshow(pic2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo='597620119.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    if (text['Id'] < 7) & (text['Confidence'] > 85):\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "        print('\\n')\n",
    "        # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_txt  = pd.DataFrame(textDetections)\n",
    "df_txt = df_txt.drop(['Geometry', 'Id', 'ParentId', 'Type'], axis=1)\n",
    "df_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_txt.groupby('DetectedText').count()\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to Get Unique Text Sets for Rekognition Dectection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_found = []\n",
    "for text in textDetections:\n",
    "    text_found.append(text['DetectedText'])\n",
    "text_set = list(set(text_found))\n",
    "text_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Rekognition with 1 and 2 Sided Test Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Cropped Text Images\n",
    "\n",
    "- Took images from PillBox and divided them to have 1 image for each side\n",
    "\n",
    "- Uploaded images into an S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "img_bucket_name = 'firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad'\n",
    "\n",
    "path = './test_images'\n",
    "# counting files uploaded\n",
    "# n_count = 0 \n",
    "\n",
    "# for filename in os.listdir(path):\n",
    "#     s3_resource.Object(img_bucket_name, \n",
    "#                        filename).upload_file(\n",
    "#                        Filename=f'./test_images/{filename}')\n",
    "#     n_count += 1\n",
    "\n",
    "# print(f'Number of files uploaded: {n_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Text from Test Images\n",
    "\n",
    "To be read in pairs (Side A & Side B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Image Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test bucket\n",
    "bucket='firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad'\n",
    "\n",
    "# Will need to take the JSON object and extract the 1 or 2 filenames\n",
    "# then pass them into a variable as a list\n",
    "photo_sides=['img7a.JPG', 'img7b.JPG']\n",
    "\n",
    "# Empty list to contain list(s) of text blob(s) extracted with \"Rekognition\"\n",
    "# Will contain a list per side (2 lists)\n",
    "all_text = []\n",
    "all_confLevels = []\n",
    "\n",
    "# Looping through each image in \"photo_sides\" list\n",
    "for photo in photo_sides:\n",
    "    # Detecting Text from Specified Image in S3 Bucket\n",
    "    response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "    # Detected Text (List of Dictionaries)\n",
    "    textDetections=response['TextDetections']\n",
    "\n",
    "    # Parsing Through Detected Text and \n",
    "    # Making list of Unique Sets of Text Dectected\n",
    "    text_found = []\n",
    "    confLevel_found = []\n",
    "    \n",
    "    for text in textDetections:\n",
    "        text_found.append(text['DetectedText'])\n",
    "        confLevel = \"{:.2f}\".format(text['Confidence']) + \"%\"\n",
    "        confLevel_found.append(confLevel)\n",
    "    \n",
    "    text_set = list(set(text_found))\n",
    "    # Appending detected text in image to \"all_text\" list\n",
    "    all_text.append(text_set)\n",
    "    all_confLevels.append(confLevel_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_confLevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_text = all_text.copy()\n",
    "reversed_text.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Image Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here It throws varying results.\n",
    "\n",
    "Will need to Limit results not just based on **\"unique\" text blobs** but also based on **confidence level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test bucket\n",
    "bucket='firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad'\n",
    "\n",
    "# Will need to take the JSON object and extract the 1 or 2 filenames\n",
    "# then pass them into a variable as a list\n",
    "photo_sides=['img4a.JPG', 'img4b.JPG']\n",
    "\n",
    "# Empty list to contain list(s) of text blob(s) extracted with \"Rekognition\"\n",
    "# Will contain a list per side (2 lists)\n",
    "all_text = []\n",
    "all_confLevels = []\n",
    "\n",
    "# Looping through each image in \"photo_sides\" list\n",
    "for photo in photo_sides:\n",
    "    # Detecting Text from Specified Image in S3 Bucket\n",
    "    response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "    # Detected Text (List of Dictionaries)\n",
    "    textDetections=response['TextDetections']\n",
    "\n",
    "    # Parsing Through Detected Text and \n",
    "    # Making list of Unique Sets of Text Dectected\n",
    "    text_found = []\n",
    "    confLevel_found = []\n",
    "    \n",
    "    for text in textDetections:\n",
    "        if text['Confidence'] > 87:\n",
    "            text_found.append(text['DetectedText'])\n",
    "            confLevel = \"{:.2f}\".format(text['Confidence']) + \"%\"\n",
    "            confLevel_found.append(confLevel)\n",
    "    \n",
    "    #text_set = list(set(text_found))\n",
    "    # Appending detected text in image to \"all_text\" list\n",
    "    all_text.append(text_found)\n",
    "    all_confLevels.append(confLevel_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence levels are higher for two 'S's and '1003'. Both above 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_confLevels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Image Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test bucket\n",
    "bucket='firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad'\n",
    "\n",
    "# Will need to take the JSON object and extract the 1 or 2 filenames\n",
    "# then pass them into a variable as a list\n",
    "photo_sides=['img4a.JPG', 'img4b.JPG']\n",
    "\n",
    "# Empty list to contain list(s) of text blob(s) extracted with \"Rekognition\"\n",
    "# Will contain a list per side (2 lists)\n",
    "all_text = []\n",
    "all_confLevels = []\n",
    "\n",
    "# Looping through each image in \"photo_sides\" list\n",
    "for photo in photo_sides:\n",
    "    # Detecting Text from Specified Image in S3 Bucket\n",
    "    response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "    # Detected Text (List of Dictionaries)\n",
    "    textDetections=response['TextDetections']\n",
    "\n",
    "    # Parsing Through Detected Text and \n",
    "    # Making list of Unique Sets of Text Dectected\n",
    "    text_found = []\n",
    "    confLevel_found = []\n",
    "    \n",
    "    for text in textDetections:\n",
    "        if text['Confidence'] > 85:\n",
    "            text_found.append(text['DetectedText'])\n",
    "            confLevel = \"{:.2f}\".format(text['Confidence']) + \"%\"\n",
    "            confLevel_found.append(confLevel)\n",
    "    \n",
    "    #text_set = list(set(text_found))\n",
    "    # Appending detected text in image to \"all_text\" list\n",
    "    all_text.append(text_found)\n",
    "    all_confLevels.append(confLevel_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_confLevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "all_split_text = []\n",
    "for text_list in all_text:\n",
    "    if len(text_list) > 0:\n",
    "        for text in text_list:\n",
    "            text_split = re.split('(\\D+)', text)\n",
    "            all_split_text.append(text_split)\n",
    "\n",
    "unique_list = []\n",
    "for each in all_split_text:\n",
    "    unique_list.append([i for i in each if i])\n",
    "    \n",
    "unique_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening list of lists returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [blob for sublist in all_text for blob in sublist]\n",
    "text_list = list(set(text_list))\n",
    "text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of text blobs split where digits and letters are together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = []\n",
    "for each in text_list:\n",
    "    num_split = re.findall(r'[A-Za-z]+|\\d+', each)\n",
    "    unique_list.append(num_split)\n",
    "    \n",
    "unique_list = [blob for sublist in unique_list for blob in sublist]\n",
    "unique_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now as a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text  Dectection Function\n",
    "def text_detection(filename_list):\n",
    "    \n",
    "    #THIS IS A TEST BUCKET\n",
    "    bucket='firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad'\n",
    "\n",
    "    # Empty list to contain list(s) of text blob(s) extracted with \"Rekognition\"\n",
    "    # Will contain a list per side (2 lists)\n",
    "    all_text = []\n",
    "\n",
    "    # Looping through each image in \"photo_sides\" list\n",
    "    for file in filename_list:\n",
    "        # Detecting Text from Specified Image in S3 Bucket\n",
    "        response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':file}})\n",
    "\n",
    "        # Detected Text (List of Dictionaries)\n",
    "        textDetections=response['TextDetections']\n",
    "\n",
    "        # Parsing Through Detected Text and \n",
    "        # Making list of Unique Sets of Text Dectected\n",
    "        text_found = []\n",
    "\n",
    "        for text in textDetections:\n",
    "            if text['Confidence'] > 87:\n",
    "                text_found.append(text['DetectedText'])\n",
    "\n",
    "        text_set = list(set(text_found))\n",
    "        \n",
    "        # Appending detected text in image to \"all_text\" list\n",
    "        all_text.append(text_set)\n",
    "        \n",
    "    # Flattening 'all_text' (list of lists) into 1 list\n",
    "    text_list = [blob for sublist in all_text for blob in sublist]\n",
    "    text_list = list(set(text_list))\n",
    "    # print(f'text_list: {text_list}')\n",
    "    \n",
    "    # Splitting any text blob that may have digits and numbers together\n",
    "    unique_list = []\n",
    "    for each in text_list:\n",
    "        num_split = re.findall(r'[A-Za-z]+|\\d+', each)\n",
    "        unique_list.append(num_split)\n",
    "        \n",
    "    # Flattening again into one list with just unique values\n",
    "    unique_list = [blob for sublist in unique_list for blob in sublist]\n",
    "    unique_list = list(set(unique_list))\n",
    "    # print(len(unique_list))\n",
    "    \n",
    "    if len(unique_list) == 0:\n",
    "        unique_list = ['Unable to detect text']\n",
    "    \n",
    "    # Return 'unique_list' as JSON    \n",
    "    return json.dumps(unique_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Detecting Text from URL Image\n",
    "\n",
    "This takes 1 image at the time - assuming each url would be an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_url = \"http://www.gunnerkrigg.com//comics/00000001.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "from skimage import color\n",
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "import boto3\n",
    "import numpy as np\n",
    "import cv2\n",
    "client=boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to increase image contrast\n",
    "def add_contrast(image_path):\n",
    "\n",
    "    #-----Reading the image-----------------------------------------------------\n",
    "    img = cv2.imread(image_path, 1)\n",
    "\n",
    "    #-----Converting image to LAB Color model----------------------------------- \n",
    "    lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    #-----Splitting the LAB image to different channels-------------------------\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    #-----Applying CLAHE to L-channel-------------------------------------------\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "\n",
    "    #-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "\n",
    "    #-----Converting image from LAB Color model to RGB model--------------------\n",
    "    image_contrast = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return image_contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text  Dectection Function\n",
    "def post_rekog(pic_json):\n",
    "    \n",
    "    # Getting list of image file names\n",
    "    imageURL_list = pic_json.get(\"image_locations\")\n",
    "    # print(f'imageURL_list {imageURL_list}')\n",
    "    \n",
    "    # text from image(s) uploaded by user\n",
    "    all_text = []\n",
    "    # text read from image(s) with contrast filter\n",
    "    all_filter_text = []\n",
    "    \n",
    "    # Looping through image(s)\n",
    "    ctr1 = 10000\n",
    "    ctr2 = 10001\n",
    "    for imageURL in imageURL_list:\n",
    "        if imageURL != \"\":\n",
    "            # Saving image URL locally\n",
    "            ctr1 += 2\n",
    "            temp_img = str(ctr1) + \".jpg\"\n",
    "            urllib.request.urlretrieve(imageURL, temp_img)\n",
    "            imageFile = './' + temp_img\n",
    "            \n",
    "            # ------------- Detecting text from original image ------------\n",
    "            \n",
    "            with open(imageFile, 'rb') as image:\n",
    "                # !!!!!!  WRAP THIS IN A TRY / CATCH !!!!!!!!!\n",
    "                response = client.detect_text(Image={'Bytes': image.read()})\n",
    "                \n",
    "#                 response2 = \n",
    "\n",
    "            # Detected Text (List of Dictionaries)\n",
    "            textDetections=response['TextDetections']\n",
    "\n",
    "            # Parsing Through Detected Text and \n",
    "            # Making list of Unique Sets of Text Dectected\n",
    "            text_found = []\n",
    "\n",
    "            for text in textDetections:\n",
    "                if text['Confidence'] > 70:\n",
    "                    text_found.append(text['DetectedText'])\n",
    "#                     print(text['Confidence'])\n",
    "#             print(f'text_found: {text_found}')\n",
    "            \n",
    "            text_set = list(set(text_found))\n",
    "\n",
    "            # Appending detected text in image to \"all_text\" list\n",
    "            all_text.append(text_set) \n",
    "            \n",
    "            # ------------- Detecting text from filtered image ------------\n",
    "            \n",
    "            filtered_img = add_contrast(imageFile)\n",
    "            \n",
    "            # Saving image URL locally\n",
    "            ctr2 += 2\n",
    "            temp_img = str(ctr2) + \".jpg\"\n",
    "            cv2.imwrite(temp_img, filtered_img)\n",
    "            imageFile2 = './' + temp_img\n",
    "            \n",
    "            with open(imageFile2, 'rb') as image:\n",
    "                # !!!!!!  WRAP THIS IN A TRY / CATCH !!!!!!!!!\n",
    "                response2 = client.detect_text(Image={'Bytes': image.read()}) \n",
    "\n",
    "            # Detected Text (List of Dictionaries)\n",
    "            textDetections2=response2['TextDetections']\n",
    "\n",
    "            # Parsing Through Detected Text and \n",
    "            # Making list of Unique Sets of Text Dectected\n",
    "            text_found2 = []\n",
    "\n",
    "            for text in textDetections2:\n",
    "                if text['Confidence'] > 0:\n",
    "                    text_found2.append(text['DetectedText'])\n",
    "#                     print(text['Confidence'])\n",
    "#             print(f'text_found: {text_found}')\n",
    "            \n",
    "            text_set2 = list(set(text_found2))\n",
    "\n",
    "            # Appending detected text in image to \"all_text\" list\n",
    "            all_filter_text.append(text_set2) \n",
    "            \n",
    "            # ------------------------------------------------------------\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # Flattening 'all_text' (list of lists) into 1 list\n",
    "    text_list = [text for sublist in all_text for text in sublist]\n",
    "    text_list = list(set(text_list))\n",
    "    \n",
    "    text_list2 = [text for sublist in all_filter_text for text in sublist]\n",
    "    text_list2 = list(set(text_list2))\n",
    "#     print(f'text_list: {text_list}')\n",
    "#     print(f'text_list2: {text_list2}')\n",
    "\n",
    "    # Splitting any text blob that may have digits and numbers together\n",
    "    unique_list = []\n",
    "    for each in text_list:\n",
    "        num_split = re.findall(r'[A-Za-z]+|\\d+', each)\n",
    "        unique_list.append(num_split)\n",
    "        \n",
    "    unique_list2 = []\n",
    "    for each in text_list2:\n",
    "        num_split = re.findall(r'[A-Za-z]+|\\d+', each)\n",
    "        unique_list2.append(num_split)\n",
    "\n",
    "    # Flattening again into one list with just unique values\n",
    "    unique_list = [text for sublist in unique_list for text in sublist]\n",
    "    unique_list = list(set(unique_list))\n",
    "    \n",
    "    unique_list2 = [text for sublist in unique_list for text in sublist]\n",
    "    unique_list2 = list(set(unique_list))\n",
    "#     print(unique_list2)\n",
    "\n",
    "    # Return 'final_list'\n",
    "    final_list = set(unique_list + unique_list2)\n",
    "    \n",
    "    # If 'final_list' is empty return and empty set instead\n",
    "    if len(final_list) == 0:\n",
    "        return {}\n",
    "    \n",
    "    # For long resulting lists get only 3! \n",
    "    # (new list length 3 will be random since it's originally a set turned to list)\n",
    "    if len(final_list) > 3:\n",
    "        final_list = set(list(final_list)[:3])\n",
    "\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO FILTER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_rekogNF(pic_json,elem_limit=3, con_fidence=70):\n",
    "    # Getting list of image file names\n",
    "    imageURL_list = pic_json.get(\"image_locations\")\n",
    "\n",
    "    # text from image(s) uploaded by user\n",
    "    all_text = []\n",
    "    \n",
    "    # Looping through image(s)\n",
    "    ctr1 = 10000\n",
    "    for imageURL in imageURL_list:\n",
    "        if imageURL != \"\":\n",
    "            # Saving image URL locally\n",
    "            ctr1 += 1\n",
    "            temp_img = str(ctr1) + \".jpg\"\n",
    "            urllib.request.urlretrieve(imageURL, temp_img)\n",
    "            imageFile = './' + temp_img\n",
    "            \n",
    "            # ------------- Detecting text from original image ------------\n",
    "            \n",
    "            with open(imageFile, 'rb') as image:\n",
    "                # !!!!!!  WRAP THIS IN A TRY / CATCH !!!!!!!!!\n",
    "                response = client.detect_text(Image={'Bytes': image.read()})\n",
    "\n",
    "            # Detected Text (List of Dictionaries)\n",
    "            textDetections = response['TextDetections']\n",
    "\n",
    "            # Parsing Through Detected Text and \n",
    "            # Making list of Unique Sets of Text Dectected\n",
    "            text_found = []\n",
    "            for text in textDetections:\n",
    "                if text['Confidence'] > con_fidence:\n",
    "                    text_found.append(text['DetectedText'])\n",
    "#                     print(text['Confidence'])\n",
    "#             print(f'text_found: {text_found}')\n",
    "            \n",
    "            text_set = list(set(text_found))\n",
    "\n",
    "            # Appending detected text in image to \"all_text\" list\n",
    "            all_text.append(text_set) \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # Flattening 'all_text' (list of lists) into 1 list\n",
    "    text_list = [text for sublist in all_text for text in sublist]\n",
    "    text_list = list(set(text_list))\n",
    "\n",
    "    # Splitting any text blob that may have digits and numbers together\n",
    "    unique_list = []\n",
    "    for each in text_list:\n",
    "        num_split = re.findall(r'[A-Za-z]+|\\d+', each)\n",
    "        unique_list.append(num_split)\n",
    "\n",
    "    # Flattening again into one list with just unique values\n",
    "    unique_list = [text for sublist in unique_list for text in sublist]\n",
    "    unique_list = list(set(unique_list))\n",
    "    # print('unique_list:\\n', unique_list)\n",
    "\n",
    "    # Return 'final_list'\n",
    "    final_list = set(unique_list)\n",
    "    # print(final_list)\n",
    "    \n",
    "    # If 'final_list' is empty return and empty set instead\n",
    "    if len(final_list) == 0:\n",
    "        return {}\n",
    "    \n",
    "    # For long resulting lists get only 3! \n",
    "    # (new list length 3 will be random since it's originally a set turned to list)\n",
    "#     if len(final_list) > elem_limit:\n",
    "#         # turning set to a list sorted by string length\n",
    "#         final_list = sorted(list(final_list), key=len)[-elem_limit:]\n",
    "#         final_list = set(final_list)\n",
    "    #print('all detected text', all_text)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing image pairs into `text_detection` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing function on URL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot detect text in this pill\n",
    "# test_url = {\"image_locations\": [\"./test_images/img4a.JPG\"]}\n",
    "\n",
    "# post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# pic1 = imageio.imread('./test_images/img4a.JPG')\n",
    "# pic2 = imageio.imread('./test_images/img4b.JPG')\n",
    "# plt.imshow(pic1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(pic2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H;126\n",
    "test_url = {\"image_locations\": [\"https://raw.githubusercontent.com/ed-chin-git/ed-chin-git.github.io/master/sample_pill_image.jpg\", \"\"]}\n",
    "\n",
    "post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image with tons of pills\n",
    "test_url = {\"image_locations\": [\"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/adderall.jpg\", \n",
    "                                \"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/adderall.jpg\"]}\n",
    "\n",
    "post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this side of the pill is without text\n",
    "test_url = {\"image_locations\":[\"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/img2b.JPG\",\n",
    "                               \"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/img2b.JPG\"]}\n",
    "\n",
    "post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = {\"image_locations\":[\"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/img5b.JPG\"]}\n",
    "\n",
    "post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url={\"image_locations\":[\"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/img8.JPG\"]}\n",
    "\n",
    "post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url={\"image_locations\":[\"https://s3.amazonaws.com/labs12-rxidstore/reference/000069117.jpg\"]}\n",
    "\n",
    "post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing function NO FILTER!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H;126\n",
    "test_url = {\"image_locations\": [\"https://raw.githubusercontent.com/ed-chin-git/ed-chin-git.github.io/master/sample_pill_image.jpg\", \"\"]}\n",
    "\n",
    "post_rekogNF(test_url, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this side of the pill is without text\n",
    "test_url = {\"image_locations\":[\"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/img2b.JPG\",\n",
    "                               \"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/img2b.JPG\"]}\n",
    "\n",
    "post_rekogNF(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image with tons of pills\n",
    "test_url = {\"image_locations\": [\"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/adderall.jpg\", \n",
    "                                \"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/adderall.jpg\"]}\n",
    "\n",
    "post_rekogNF(test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will turning the Object from S3 into grayscale help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "from skimage import color\n",
    "obj_key = 'img3a.JPG'\n",
    "obj = s3_resource.Object(bucket, obj_key)\n",
    "obj_body = obj.get()['Body'].read()\n",
    "\n",
    "photo = imageio.imread(obj_body)\n",
    "bw_photo = rescale_intensity(color.rgb2gray(photo))\n",
    "\n",
    "plt.imshow(bw_photo);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS --> Analyzing an Image Loaded from a Local File System\n",
    "\n",
    "https://docs.aws.amazon.com/rekognition/latest/dg/images-bytes.html\n",
    "\n",
    "The following AWS SDK for Python example shows how to load an image from the local file system and call the detect_labels operation. Change the value of imageFile to the path and file name of an image file (.jpg or .png format).\n",
    "\n",
    "```\n",
    "import boto3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    imageFile='input.jpg'\n",
    "    client=boto3.client('rekognition')\n",
    "   \n",
    "    with open(imageFile, 'rb') as image:\n",
    "        response = client.detect_labels(Image={'Bytes': image.read()})\n",
    "        \n",
    "    print('Detected labels in ' + imageFile)    \n",
    "    for label in response['Labels']:\n",
    "        print (label['Name'] + ' : ' + str(label['Confidence']))\n",
    "\n",
    "    print('Done...')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://s3.amazonaws.com/rxid-images/uploads/00002-4462-30_B215591A.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting text from local image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFile='./test_images/img3b_contrast.JPG'\n",
    "\n",
    "with open(imageFile, 'rb') as image:\n",
    "    response = client.detect_text(Image={'Bytes': image.read()})\n",
    "        \n",
    "print('Detected labels in ' + imageFile)    \n",
    "for text in response['TextDetections']:\n",
    "    print (text['DetectedText'] + ' : ' + str(text['Confidence']))\n",
    "\n",
    "\n",
    "# textDetections=response['TextDetections']\n",
    "# print ('Detected text')\n",
    "# for text in textDetections:\n",
    "#     print ('Detected text:' + text['DetectedText'])\n",
    "#     print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "#     print('\\n')\n",
    "    # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting text from ulr image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "...\n",
    "# Download the file from `url` and save it locally under `file_name`:\n",
    "urllib.request.urlretrieve(\"http://www.gunnerkrigg.com//comics/00000001.jpg\", \"00000001.jpg\")\n",
    "imageFile='./00000001.jpg'\n",
    "\n",
    "with open(imageFile, 'rb') as image:\n",
    "    response = client.detect_text(Image={'Bytes': image.read()})\n",
    "        \n",
    "print('Detected labels in ' + imageFile)    \n",
    "for text in response['TextDetections']:\n",
    "    print (text['DetectedText'] + ' : ' + str(text['Confidence']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}