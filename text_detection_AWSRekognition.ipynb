{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Rekognition Text Detection Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3_resource = boto3.resource('s3')\n",
    "client=boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='secondpythonbucket6ce9cccf-c429-471c-99a1-f36e849ee381'\n",
    "photo='00007-4883-13_DB18ED97.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    if text['Id'] < 7:\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "        print('\\n')\n",
    "        # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pill_img = imageio.imread('./pillbox_images/00007-4883-13_DB18ED97.jpg')\n",
    "plt.imshow(pill_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo='009045988.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    #if text['Id'] < 7:\n",
    "    print ('Detected text:' + text['DetectedText'])\n",
    "    print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "    print('\\n')\n",
    "    # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pill_img = imageio.imread('./pillbox_images/009045988.jpg')\n",
    "plt.imshow(pill_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo='006035484.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    if (text['Id'] < 7) & (text['Confidence'] > 85):\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "        print('\\n')\n",
    "        # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pill_img = imageio.imread('./pillbox_images/006035484.jpg')\n",
    "plt.imshow(pill_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo='007773107.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    if (text['Id'] < 7) & (text['Confidence'] > 85):\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "        print('\\n')\n",
    "        # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pill_img = imageio.imread('./pillbox_images/007773107.jpg')\n",
    "plt.imshow(pill_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to manipulate an image from S3 Bucket\n",
    "\n",
    "We'll try to cut the image in half to split into 2 images \n",
    "(To mimic a scenario where a user will send pictures of front and back of pill)\n",
    "\n",
    "Then we'll seek to read text from each and keep unique pieces of text (but only those with \"Confidence\" > 85%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo='007811655.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    if (text['Id'] < 7) & (text['Confidence'] > 85):\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "        print('\\n')\n",
    "        # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get url of file uploaded on AWS S3 bucket?\n",
    "\n",
    "https://region_name.amazonaws.com/buket_name/object_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Image from S3 and Splitting into 2 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading image\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "s3_resource.Object(bucket, photo).download_file(f'./{photo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pic = imageio.imread('./007811655.jpg')\n",
    "plt.imshow(pic);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = pic.shape[:2]\n",
    "\n",
    "# Cut the image in half\n",
    "height_cutoff = height // 2\n",
    "s1 = pic[:height_cutoff,:]\n",
    "s2 = pic[height_cutoff:,:]\n",
    "\n",
    "# Save each half\n",
    "imageio.imwrite('img1.png', s1)\n",
    "imageio.imwrite('img2.png', s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic1 = imageio.imread('./img1.png')\n",
    "plt.imshow(pic1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic2 = imageio.imread('./img2.png')\n",
    "plt.imshow(pic2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo='597620119.jpg'\n",
    "\n",
    "response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "textDetections=response['TextDetections']\n",
    "print ('Detected text')\n",
    "for text in textDetections:\n",
    "    if (text['Id'] < 7) & (text['Confidence'] > 85):\n",
    "        print ('Detected text:' + text['DetectedText'])\n",
    "        print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "        print('\\n')\n",
    "        # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_txt  = pd.DataFrame(textDetections)\n",
    "df_txt = df_txt.drop(['Geometry', 'Id', 'ParentId', 'Type'], axis=1)\n",
    "df_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_txt.groupby('DetectedText').count()\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to Get Unique Text Sets for Rekognition Dectection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_found = []\n",
    "for text in textDetections:\n",
    "    text_found.append(text['DetectedText'])\n",
    "text_set = list(set(text_found))\n",
    "text_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Rekognition with 1 and 2 Sided Test Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Cropped Text Images\n",
    "\n",
    "- Took images from PillBox and divided them to have 1 image for each side\n",
    "\n",
    "- Uploaded images into an S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "img_bucket_name = 'firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad'\n",
    "\n",
    "path = './test_images'\n",
    "# counting files uploaded\n",
    "# n_count = 0 \n",
    "\n",
    "# for filename in os.listdir(path):\n",
    "#     s3_resource.Object(img_bucket_name, \n",
    "#                        filename).upload_file(\n",
    "#                        Filename=f'./test_images/{filename}')\n",
    "#     n_count += 1\n",
    "\n",
    "# print(f'Number of files uploaded: {n_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Text from Test Images\n",
    "\n",
    "To be read in pairs (Side A & Side B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Image Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test bucket\n",
    "bucket='firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad'\n",
    "\n",
    "# Will need to take the JSON object and extract the 1 or 2 filenames\n",
    "# then pass them into a variable as a list\n",
    "photo_sides=['img7a.JPG', 'img7b.JPG']\n",
    "\n",
    "# Empty list to contain list(s) of text blob(s) extracted with \"Rekognition\"\n",
    "# Will contain a list per side (2 lists)\n",
    "all_text = []\n",
    "all_confLevels = []\n",
    "\n",
    "# Looping through each image in \"photo_sides\" list\n",
    "for photo in photo_sides:\n",
    "    # Detecting Text from Specified Image in S3 Bucket\n",
    "    response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "    # Detected Text (List of Dictionaries)\n",
    "    textDetections=response['TextDetections']\n",
    "\n",
    "    # Parsing Through Detected Text and \n",
    "    # Making list of Unique Sets of Text Dectected\n",
    "    text_found = []\n",
    "    confLevel_found = []\n",
    "    \n",
    "    for text in textDetections:\n",
    "        text_found.append(text['DetectedText'])\n",
    "        confLevel = \"{:.2f}\".format(text['Confidence']) + \"%\"\n",
    "        confLevel_found.append(confLevel)\n",
    "    \n",
    "    text_set = list(set(text_found))\n",
    "    # Appending detected text in image to \"all_text\" list\n",
    "    all_text.append(text_set)\n",
    "    all_confLevels.append(confLevel_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_confLevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_text = all_text.copy()\n",
    "reversed_text.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Image Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here It throws varying results.\n",
    "\n",
    "Will need to Limit results not just based on **\"unique\" text blobs** but also based on **confidence level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test bucket\n",
    "bucket='firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad'\n",
    "\n",
    "# Will need to take the JSON object and extract the 1 or 2 filenames\n",
    "# then pass them into a variable as a list\n",
    "photo_sides=['img4a.JPG', 'img4b.JPG']\n",
    "\n",
    "# Empty list to contain list(s) of text blob(s) extracted with \"Rekognition\"\n",
    "# Will contain a list per side (2 lists)\n",
    "all_text = []\n",
    "all_confLevels = []\n",
    "\n",
    "# Looping through each image in \"photo_sides\" list\n",
    "for photo in photo_sides:\n",
    "    # Detecting Text from Specified Image in S3 Bucket\n",
    "    response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "    # Detected Text (List of Dictionaries)\n",
    "    textDetections=response['TextDetections']\n",
    "\n",
    "    # Parsing Through Detected Text and \n",
    "    # Making list of Unique Sets of Text Dectected\n",
    "    text_found = []\n",
    "    confLevel_found = []\n",
    "    \n",
    "    for text in textDetections:\n",
    "        if text['Confidence'] > 87:\n",
    "            text_found.append(text['DetectedText'])\n",
    "            confLevel = \"{:.2f}\".format(text['Confidence']) + \"%\"\n",
    "            confLevel_found.append(confLevel)\n",
    "    \n",
    "    #text_set = list(set(text_found))\n",
    "    # Appending detected text in image to \"all_text\" list\n",
    "    all_text.append(text_found)\n",
    "    all_confLevels.append(confLevel_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence levels are higher for two 'S's and '1003'. Both above 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_confLevels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Image Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test bucket\n",
    "bucket='firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad'\n",
    "\n",
    "# Will need to take the JSON object and extract the 1 or 2 filenames\n",
    "# then pass them into a variable as a list\n",
    "photo_sides=['img4a.JPG', 'img4b.JPG']\n",
    "\n",
    "# Empty list to contain list(s) of text blob(s) extracted with \"Rekognition\"\n",
    "# Will contain a list per side (2 lists)\n",
    "all_text = []\n",
    "all_confLevels = []\n",
    "\n",
    "# Looping through each image in \"photo_sides\" list\n",
    "for photo in photo_sides:\n",
    "    # Detecting Text from Specified Image in S3 Bucket\n",
    "    response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':photo}})\n",
    "\n",
    "    # Detected Text (List of Dictionaries)\n",
    "    textDetections=response['TextDetections']\n",
    "\n",
    "    # Parsing Through Detected Text and \n",
    "    # Making list of Unique Sets of Text Dectected\n",
    "    text_found = []\n",
    "    confLevel_found = []\n",
    "    \n",
    "    for text in textDetections:\n",
    "        if text['Confidence'] > 85:\n",
    "            text_found.append(text['DetectedText'])\n",
    "            confLevel = \"{:.2f}\".format(text['Confidence']) + \"%\"\n",
    "            confLevel_found.append(confLevel)\n",
    "    \n",
    "    #text_set = list(set(text_found))\n",
    "    # Appending detected text in image to \"all_text\" list\n",
    "    all_text.append(text_found)\n",
    "    all_confLevels.append(confLevel_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_confLevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "all_split_text = []\n",
    "for text_list in all_text:\n",
    "    if len(text_list) > 0:\n",
    "        for text in text_list:\n",
    "            text_split = re.split('(\\D+)', text)\n",
    "            all_split_text.append(text_split)\n",
    "\n",
    "unique_list = []\n",
    "for each in all_split_text:\n",
    "    unique_list.append([i for i in each if i])\n",
    "    \n",
    "unique_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening list of lists returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [blob for sublist in all_text for blob in sublist]\n",
    "text_list = list(set(text_list))\n",
    "text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of text blobs split where digits and letters are together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = []\n",
    "for each in text_list:\n",
    "    num_split = re.findall(r'[A-Za-z]+|\\d+', each)\n",
    "    unique_list.append(num_split)\n",
    "    \n",
    "unique_list = [blob for sublist in unique_list for blob in sublist]\n",
    "unique_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now as a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text  Dectection Function\n",
    "def text_detection(filename_list):\n",
    "    \n",
    "    #THIS IS A TEST BUCKET\n",
    "    bucket='firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad'\n",
    "\n",
    "    # Empty list to contain list(s) of text blob(s) extracted with \"Rekognition\"\n",
    "    # Will contain a list per side (2 lists)\n",
    "    all_text = []\n",
    "\n",
    "    # Looping through each image in \"photo_sides\" list\n",
    "    for file in filename_list:\n",
    "        # Detecting Text from Specified Image in S3 Bucket\n",
    "        response=client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':file}})\n",
    "\n",
    "        # Detected Text (List of Dictionaries)\n",
    "        textDetections=response['TextDetections']\n",
    "\n",
    "        # Parsing Through Detected Text and \n",
    "        # Making list of Unique Sets of Text Dectected\n",
    "        text_found = []\n",
    "\n",
    "        for text in textDetections:\n",
    "            if text['Confidence'] > 87:\n",
    "                text_found.append(text['DetectedText'])\n",
    "\n",
    "        text_set = list(set(text_found))\n",
    "        \n",
    "        # Appending detected text in image to \"all_text\" list\n",
    "        all_text.append(text_set)\n",
    "        \n",
    "    # Flattening 'all_text' (list of lists) into 1 list\n",
    "    text_list = [blob for sublist in all_text for blob in sublist]\n",
    "    text_list = list(set(text_list))\n",
    "    # print(f'text_list: {text_list}')\n",
    "    \n",
    "    # Splitting any text blob that may have digits and numbers together\n",
    "    unique_list = []\n",
    "    for each in text_list:\n",
    "        num_split = re.findall(r'[A-Za-z]+|\\d+', each)\n",
    "        unique_list.append(num_split)\n",
    "        \n",
    "    # Flattening again into one list with just unique values\n",
    "    unique_list = [blob for sublist in unique_list for blob in sublist]\n",
    "    unique_list = list(set(unique_list))\n",
    "    # print(len(unique_list))\n",
    "    \n",
    "    if len(unique_list) == 0:\n",
    "        unique_list = ['Unable to detect text']\n",
    "    \n",
    "    # Return 'unique_list' as JSON    \n",
    "    return json.dumps(unique_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Detecting Text from URL Image\n",
    "\n",
    "This takes 1 image at the time - assuming each url would be an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_url = \"http://www.gunnerkrigg.com//comics/00000001.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "from skimage import color\n",
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "import boto3\n",
    "import numpy as np\n",
    "client=boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE THIS A FUNCTION!!!\n",
    "\n",
    "# !!!!!!  WRAP THIS IN A TRY / CATCH !!!!!!!!!\n",
    "\n",
    "#-----Reading the image-----------------------------------------------------\n",
    "img = cv2.imread('./test_images/img1a.JPG', 1)\n",
    "\n",
    "#-----Converting image to LAB Color model----------------------------------- \n",
    "lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "#-----Splitting the LAB image to different channels-------------------------\n",
    "l, a, b = cv2.split(lab)\n",
    "\n",
    "#-----Applying CLAHE to L-channel-------------------------------------------\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "cl = clahe.apply(l)\n",
    "plt.imshow(cl);\n",
    "\n",
    "#-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\n",
    "limg = cv2.merge((cl,a,b))\n",
    "plt.imshow(limg);\n",
    "\n",
    "#-----Converting image from LAB Color model to RGB model--------------------\n",
    "final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "plt.imshow(final);\n",
    "\n",
    "#-----Detecting text with Rekognition---------------------------------------\n",
    "response = client.detect_text(Image={'Bytes': image.read()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text  Dectection Function\n",
    "def post_rekog(pic_json):\n",
    "    \n",
    "    # Getting list of image file names\n",
    "    imageURL_list = pic_json.get(\"image_locations\")\n",
    "    # print(f'imageURL_list {imageURL_list}')\n",
    "    \n",
    "    # Empty list to contain list(s) of text blob(s) extracted with \"Rekognition\"\n",
    "    # Will contain a list per side (2 lists)\n",
    "    all_text = []\n",
    "    \n",
    "    # Looping through each image\n",
    "    ctr = 10000\n",
    "    for imageURL in imageURL_list:\n",
    "        if imageURL != \"\":\n",
    "            # Saving image URL locally\n",
    "            ctr += 1\n",
    "            temp_img = str(ctr) + \".jpg\"\n",
    "            urllib.request.urlretrieve(imageURL, temp_img)\n",
    "            imageFile = './' + temp_img\n",
    "            \n",
    "            # Opening locally saved 'imageFile'\n",
    "            with open(imageFile, 'rb') as image:\n",
    "                # !!!!!!  WRAP THIS IN A TRY / CATCH !!!!!!!!!\n",
    "                response = client.detect_text(Image={'Bytes': image.read()})\n",
    "                \n",
    "                response2 = \n",
    "\n",
    "            # Detected Text (List of Dictionaries)\n",
    "            textDetections=response['TextDetections']\n",
    "\n",
    "            # Parsing Through Detected Text and \n",
    "            # Making list of Unique Sets of Text Dectected\n",
    "            text_found = []\n",
    "\n",
    "            for text in textDetections:\n",
    "                if text['Confidence'] > 50:\n",
    "                    text_found.append(text['DetectedText'])\n",
    "                    print(text['Confidence'])\n",
    "            print(f'text_found: {text_found}')\n",
    "            \n",
    "            text_set = list(set(text_found))\n",
    "\n",
    "            # Appending detected text in image to \"all_text\" list\n",
    "            all_text.append(text_set) \n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # Flattening 'all_text' (list of lists) into 1 list\n",
    "    text_list = [blob for sublist in all_text for blob in sublist]\n",
    "    text_list = list(set(text_list))\n",
    "    # print(f'text_list: {text_list}')\n",
    "\n",
    "    # Splitting any text blob that may have digits and numbers together\n",
    "    unique_list = []\n",
    "    for each in text_list:\n",
    "        num_split = re.findall(r'[A-Za-z]+|\\d+', each)\n",
    "        unique_list.append(num_split)\n",
    "\n",
    "    # Flattening again into one list with just unique values\n",
    "    unique_list = [blob for sublist in unique_list for blob in sublist]\n",
    "    unique_list = list(set(unique_list))\n",
    "    # print(len(unique_list))\n",
    "\n",
    "    if len(unique_list) == 0:\n",
    "        unique_list = ['Unable to detect text']\n",
    "\n",
    "    # Return 'unique_list'    \n",
    "    return (unique_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing image pairs into `text_detection` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing function on URL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot detect text in this pill\n",
    "# test_url = {\"image_locations\": [\"./test_images/img4a.JPG\"]}\n",
    "\n",
    "# post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# pic1 = imageio.imread('./test_images/img4a.JPG')\n",
    "# pic2 = imageio.imread('./test_images/img4b.JPG')\n",
    "# plt.imshow(pic1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(pic2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['126', 'H']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cannot detect text in this pill\n",
    "test_url = {\"image_locations\": [\"https://raw.githubusercontent.com/ed-chin-git/ed-chin-git.github.io/master/sample_pill_image.jpg\", \"\"]}\n",
    "\n",
    "post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unable to detect text']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this side of the pill is without text\n",
    "test_url = {\"image_locations\":[\"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/img2b.JPG\"]}\n",
    "\n",
    "post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mg', 'I', '4339', '10']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_url = {\"image_locations\":[\"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/img5b.JPG\"]}\n",
    "\n",
    "post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.4571304321289\n",
      "73.0343246459961\n",
      "92.4571304321289\n",
      "73.0343246459961\n",
      "text_found: ['20', '37', '20', '37']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['20', '37']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_url={\"image_locations\":[\"https://s3.us-east-2.amazonaws.com/firstpythonbucketac60bb97-95e1-43e5-98e6-0ca294ec9aad/img8.JPG\"]}\n",
    "\n",
    "post_rekog(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will turning the Object from S3 into grayscale help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "from skimage import color\n",
    "obj_key = 'img3a.JPG'\n",
    "obj = s3_resource.Object(bucket, obj_key)\n",
    "obj_body = obj.get()['Body'].read()\n",
    "\n",
    "photo = imageio.imread(obj_body)\n",
    "bw_photo = rescale_intensity(color.rgb2gray(photo))\n",
    "\n",
    "plt.imshow(bw_photo);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS --> Analyzing an Image Loaded from a Local File System\n",
    "\n",
    "https://docs.aws.amazon.com/rekognition/latest/dg/images-bytes.html\n",
    "\n",
    "The following AWS SDK for Python example shows how to load an image from the local file system and call the detect_labels operation. Change the value of imageFile to the path and file name of an image file (.jpg or .png format).\n",
    "\n",
    "```\n",
    "import boto3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    imageFile='input.jpg'\n",
    "    client=boto3.client('rekognition')\n",
    "   \n",
    "    with open(imageFile, 'rb') as image:\n",
    "        response = client.detect_labels(Image={'Bytes': image.read()})\n",
    "        \n",
    "    print('Detected labels in ' + imageFile)    \n",
    "    for label in response['Labels']:\n",
    "        print (label['Name'] + ' : ' + str(label['Confidence']))\n",
    "\n",
    "    print('Done...')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://s3.amazonaws.com/rxid-images/uploads/00002-4462-30_B215591A.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting text from local image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected labels in ./test_images/img3b_contrast.JPG\n",
      "988 : 75.5133056640625\n",
      "988 : 75.5133056640625\n"
     ]
    }
   ],
   "source": [
    "imageFile='./test_images/img3b_contrast.JPG'\n",
    "\n",
    "with open(imageFile, 'rb') as image:\n",
    "    response = client.detect_text(Image={'Bytes': image.read()})\n",
    "        \n",
    "print('Detected labels in ' + imageFile)    \n",
    "for text in response['TextDetections']:\n",
    "    print (text['DetectedText'] + ' : ' + str(text['Confidence']))\n",
    "\n",
    "\n",
    "# textDetections=response['TextDetections']\n",
    "# print ('Detected text')\n",
    "# for text in textDetections:\n",
    "#     print ('Detected text:' + text['DetectedText'])\n",
    "#     print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n",
    "#     print('\\n')\n",
    "    # print ('Id: {}'.format(text['Id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting text from ulr image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "...\n",
    "# Download the file from `url` and save it locally under `file_name`:\n",
    "urllib.request.urlretrieve(\"http://www.gunnerkrigg.com//comics/00000001.jpg\", \"00000001.jpg\")\n",
    "imageFile='./00000001.jpg'\n",
    "\n",
    "with open(imageFile, 'rb') as image:\n",
    "    response = client.detect_text(Image={'Bytes': image.read()})\n",
    "        \n",
    "print('Detected labels in ' + imageFile)    \n",
    "for text in response['TextDetections']:\n",
    "    print (text['DetectedText'] + ' : ' + str(text['Confidence']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
